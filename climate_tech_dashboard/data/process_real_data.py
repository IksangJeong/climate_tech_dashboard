import pandas as pd
from pathlib import Path
import numpy as np

class RealDataProcessor:
    def __init__(self):
        self.raw_dir = Path('assets/data/raw')
        self.processed_dir = Path('assets/data/processed')
        self.processed_dir.mkdir(parents=True, exist_ok=True)
        
    def process_all_data(self):
        """ëª¨ë“  ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬"""
        print("ğŸš€ ì‹¤ì œ KOSIS ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
        print("=" * 50)
        
        # 1. ê¸°ê´€ ë°ì´í„° í†µí•©
        self.process_institution_data()
        
        # 2. íŠ¹í—ˆ ë°ì´í„° ì²˜ë¦¬
        self.process_patent_data()
        
        # 3. ìˆ˜ëª…ì£¼ê¸° ë°ì´í„° ì²˜ë¦¬
        self.process_lifecycle_data()
        
        # 4. í•´ì™¸ì§„ì¶œ ë°ì´í„° ì²˜ë¦¬
        self.process_overseas_data()
        
        print("\nğŸ‰ ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ!")
        self.verify_processed_data()
    
    def read_csv_safely(self, file_path):
        """ì•ˆì „í•œ CSV ì½ê¸°"""
        encodings = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr']
        
        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                print(f"   âœ… {encoding} ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸° ì„±ê³µ: {df.shape}")
                return df
            except Exception as e:
                continue
        
        print(f"   âŒ ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨: {file_path.name}")
        return None
    
    def process_institution_data(self):
        """ê¸°ê´€ ë°ì´í„° í†µí•© ì²˜ë¦¬"""
        print("\nğŸ“Š ê¸°ê´€ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        
        # ê¸°ê´€ ê´€ë ¨ íŒŒì¼ë“¤
        institution_files = {
            'revenue': 'institution_revenue.csv',
            'employees': 'institution_employees.csv',
            'researchers': 'institution_researchers.csv',
            'rd_cost': 'institution_rd_cost.csv'
        }
        
        # ê° íŒŒì¼ ì½ê¸°
        data_dict = {}
        for metric, filename in institution_files.items():
            file_path = self.raw_dir / filename
            if file_path.exists():
                df = self.read_csv_safely(file_path)
                if df is not None:
                    data_dict[metric] = df
                    print(f"   ğŸ“„ {filename}: {df.shape}")
            else:
                print(f"   âŒ {filename} íŒŒì¼ ì—†ìŒ")
        
        if data_dict:
            # ë°ì´í„° í†µí•©
            integrated_data = self.integrate_institution_data(data_dict)
            
            # ì €ì¥
            output_file = self.processed_dir / 'institution_data.csv'
            integrated_data.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"   âœ… í†µí•© íŒŒì¼ ì €ì¥: {output_file} ({len(integrated_data)}í–‰)")
        else:
            print("   âŒ ì²˜ë¦¬í•  ê¸°ê´€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def integrate_institution_data(self, data_dict):
        """ê¸°ê´€ ë°ì´í„° í†µí•©"""
        print("   ğŸ”— ë°ì´í„° í†µí•© ì¤‘...")
        
        integrated_rows = []
        
        # ì²« ë²ˆì§¸ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ êµ¬ì¡° íŒŒì•…
        first_key = list(data_dict.keys())[0]
        base_df = data_dict[first_key]
        
        print(f"   ğŸ“‹ ê¸°ì¤€ ë°ì´í„°: {first_key}")
        print(f"   ğŸ“Š ì»¬ëŸ¼: {base_df.columns.tolist()}")
        
        # ê° í–‰ì„ ì²˜ë¦¬
        for idx, row in base_df.iterrows():
            if idx == 0:  # í—¤ë” í–‰ì€ ê±´ë„ˆë›°ê¸°
                continue
                
            try:
                # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ (ì²« ë²ˆì§¸, ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì—ì„œ)
                if len(row) >= 2:
                    field_info = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
                    scale_info = str(row.iloc[1]) if pd.notna(row.iloc[1]) else ""
                    
                    # ì—°ë„ë³„ ë°ì´í„° ì¶”ì¶œ (ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ë“¤)
                    for col_idx, value in enumerate(row.iloc[2:], 2):
                        if pd.notna(value) and str(value).replace('.', '').replace(',', '').isdigit():
                            # ê°€ëŠ¥í•œ ì—°ë„ ì¶”ì •
                            year = 2019 + (col_idx - 2) % 4  # 2019, 2020, 2021, 2022 ìˆœí™˜
                            
                            # í†µí•© í–‰ ìƒì„±
                            integrated_row = {
                                'year': year,
                                'field': self.clean_field_name(field_info),
                                'scale': self.clean_scale_name(scale_info),
                                'tech_type': 'ì „ì²´',  # ê¸°ë³¸ê°’
                                first_key: float(str(value).replace(',', '')) if str(value).replace(',', '').replace('.', '').isdigit() else 0
                            }
                            
                            # ë‹¤ë¥¸ ë©”íŠ¸ë¦­ ë°ì´í„°ë„ ì¶”ê°€
                            for metric, df in data_dict.items():
                                if metric != first_key and idx < len(df):
                                    try:
                                        other_value = df.iloc[idx, col_idx] if col_idx < len(df.columns) else 0
                                        if pd.notna(other_value):
                                            integrated_row[metric] = float(str(other_value).replace(',', '')) if str(other_value).replace(',', '').replace('.', '').isdigit() else 0
                                        else:
                                            integrated_row[metric] = 0
                                    except:
                                        integrated_row[metric] = 0
                            
                            integrated_rows.append(integrated_row)
                            
            except Exception as e:
                continue
        
        # DataFrame ìƒì„±
        if integrated_rows:
            df = pd.DataFrame(integrated_rows)
            
            # ë°ì´í„° ì •ì œ
            df = df[df['year'].between(2019, 2022)]  # ìœ íš¨í•œ ì—°ë„ë§Œ
            df = df.dropna(subset=[first_key])  # ì£¼ìš” ë©”íŠ¸ë¦­ì´ ìˆëŠ” í–‰ë§Œ
            
            # ëˆ„ë½ëœ ì»¬ëŸ¼ ê¸°ë³¸ê°’ ì„¤ì •
            required_cols = ['revenue', 'employees', 'researchers', 'rd_cost']
            for col in required_cols:
                if col not in df.columns:
                    df[col] = 0
            
            print(f"   âœ… í†µí•© ì™„ë£Œ: {len(df)}í–‰")
            return df
        else:
            print("   âŒ í†µí•© ë°ì´í„° ìƒì„± ì‹¤íŒ¨")
            return pd.DataFrame()
    
    def clean_field_name(self, field_str):
        """ë¶„ì•¼ëª… ì •ì œ"""
        field_str = str(field_str).strip()
        
        if 'ê°ì¶•' in field_str:
            return 'ê°ì¶•'
        elif 'ì ì‘' in field_str:
            return 'ì ì‘'
        elif 'ìœµë³µí•©' in field_str or 'ìœµí•©' in field_str:
            return 'ìœµë³µí•©'
        else:
            return 'ê¸°íƒ€'
    
    def clean_scale_name(self, scale_str):
        """ê·œëª¨ëª… ì •ì œ"""
        scale_str = str(scale_str).strip()
        
        if 'ëŒ€ê¸°ì—…' in scale_str or 'ëŒ€ê·œëª¨' in scale_str:
            return 'ëŒ€ê¸°ì—…'
        elif 'ì¤‘ê¸°ì—…' in scale_str or 'ì¤‘ê·œëª¨' in scale_str:
            return 'ì¤‘ê¸°ì—…'
        elif 'ì†Œê¸°ì—…' in scale_str or 'ì†Œê·œëª¨' in scale_str:
            return 'ì†Œê¸°ì—…'
        elif 'ì—°êµ¬' in scale_str:
            return 'ì—°êµ¬ê¸°ê´€'
        else:
            return 'ê¸°íƒ€'
    
    def process_patent_data(self):
        """íŠ¹í—ˆ ë°ì´í„° ì²˜ë¦¬"""
        print("\nğŸ“‹ íŠ¹í—ˆ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        
        file_path = self.raw_dir / 'patent_data.csv'
        if not file_path.exists():
            print("   âŒ patent_data.csv íŒŒì¼ ì—†ìŒ")
            return
        
        df = self.read_csv_safely(file_path)
        if df is None:
            return
        
        # íŠ¹í—ˆ ë°ì´í„° êµ¬ì¡° ë³€í™˜
        processed_data = []
        
        for idx, row in df.iterrows():
            if idx == 0:  # í—¤ë” ê±´ë„ˆë›°ê¸°
                continue
                
            try:
                field_info = str(row.iloc[0]) if len(row) > 0 and pd.notna(row.iloc[0]) else ""
                tech_info = str(row.iloc[1]) if len(row) > 1 and pd.notna(row.iloc[1]) else ""
                
                # ì—°ë„ë³„ ë°ì´í„° ì²˜ë¦¬
                for col_idx in range(2, min(len(row), 6)):  # ìµœëŒ€ 4ë…„ì¹˜ ë°ì´í„°
                    if pd.notna(row.iloc[col_idx]):
                        value = str(row.iloc[col_idx]).replace(',', '')
                        if value.replace('.', '').isdigit():
                            processed_data.append({
                                'year': 2019 + (col_idx - 2),
                                'field': self.clean_field_name(field_info),
                                'tech_name': tech_info,
                                'patent_count': int(float(value)),
                                'category': self.clean_field_name(field_info)
                            })
            except:
                continue
        
        if processed_data:
            result_df = pd.DataFrame(processed_data)
            output_file = self.processed_dir / 'patent_data.csv'
            result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"   âœ… íŠ¹í—ˆ ë°ì´í„° ì €ì¥: {output_file} ({len(result_df)}í–‰)")
        else:
            print("   âŒ íŠ¹í—ˆ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
    
    def process_lifecycle_data(self):
        """ìˆ˜ëª…ì£¼ê¸° ë°ì´í„° ì²˜ë¦¬"""
        print("\nğŸ”„ ìˆ˜ëª…ì£¼ê¸° ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        
        file_path = self.raw_dir / 'lifecycle_data.csv'
        if not file_path.exists():
            print("   âŒ lifecycle_data.csv íŒŒì¼ ì—†ìŒ")
            return
        
        df = self.read_csv_safely(file_path)
        if df is None:
            return
        
        # ìˆ˜ëª…ì£¼ê¸° ë‹¨ê³„
        lifecycle_stages = ['ê¸°ì´ˆì—°êµ¬', 'ì‘ìš©ì—°êµ¬', 'ê°œë°œì—°êµ¬', 'ì‹œì œí’ˆì œì‘', 
                           'ì‚¬ì—…í™”ì¤€ë¹„', 'ì‹œì¥ì§„ì…', 'ì‹œì¥í™•ì‚°', 'ì„±ìˆ™ê¸°']
        
        processed_data = []
        
        for idx, row in df.iterrows():
            if idx == 0:
                continue
                
            try:
                field_info = str(row.iloc[0]) if len(row) > 0 and pd.notna(row.iloc[0]) else ""
                tech_info = str(row.iloc[1]) if len(row) > 1 and pd.notna(row.iloc[1]) else ""
                
                # ê° ìˆ˜ëª…ì£¼ê¸° ë‹¨ê³„ë³„ ë°ì´í„°
                for stage_idx, stage in enumerate(lifecycle_stages):
                    if stage_idx + 2 < len(row) and pd.notna(row.iloc[stage_idx + 2]):
                        value = str(row.iloc[stage_idx + 2]).replace(',', '')
                        if value.replace('.', '').isdigit():
                            processed_data.append({
                                'year': 2020,  # ê¸°ë³¸ ì—°ë„
                                'field': self.clean_field_name(field_info),
                                'tech_name': tech_info,
                                'lifecycle_stage': stage,
                                'project_count': int(float(value)),
                                'stage_order': stage_idx + 1
                            })
            except:
                continue
        
        if processed_data:
            result_df = pd.DataFrame(processed_data)
            output_file = self.processed_dir / 'lifecycle_data.csv'
            result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"   âœ… ìˆ˜ëª…ì£¼ê¸° ë°ì´í„° ì €ì¥: {output_file} ({len(result_df)}í–‰)")
        else:
            print("   âŒ ìˆ˜ëª…ì£¼ê¸° ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
    
    def process_overseas_data(self):
        """í•´ì™¸ì§„ì¶œ ë°ì´í„° ì²˜ë¦¬"""
        print("\nğŸŒ í•´ì™¸ì§„ì¶œ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        
        file_path = self.raw_dir / 'overseas_data.csv'
        if not file_path.exists():
            print("   âŒ overseas_data.csv íŒŒì¼ ì—†ìŒ")
            return
        
        df = self.read_csv_safely(file_path)
        if df is None:
            return
        
        # ì§€ì—­ ì¢Œí‘œ ë§¤í•‘
        region_coords = {
            'ë™ë‚¨ì•„ì‹œì•„': (10.0, 110.0, 'ë² íŠ¸ë‚¨, íƒœêµ­, ì¸ë„ë„¤ì‹œì•„'),
            'ì¤‘êµ­': (35.0, 104.0, 'ì¤‘êµ­'),
            'ì¼ë³¸': (36.0, 138.0, 'ì¼ë³¸'),
            'ìœ ëŸ½': (54.0, 15.0, 'ë…ì¼, í”„ë‘ìŠ¤, ì˜êµ­'),
            'ë¶ë¯¸': (45.0, -100.0, 'ë¯¸êµ­, ìºë‚˜ë‹¤'),
            'ì¤‘ë™': (25.0, 45.0, 'UAE, ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„'),
            'ë‚¨ë¯¸': (-15.0, -60.0, 'ë¸Œë¼ì§ˆ, ì•„ë¥´í—¨í‹°ë‚˜'),
            'ì•„í”„ë¦¬ì¹´': (0.0, 20.0, 'ë‚¨ì•„í”„ë¦¬ì¹´ê³µí™”êµ­, ì´ì§‘íŠ¸')
        }
        
        processed_data = []
        
        for idx, row in df.iterrows():
            if idx == 0:
                continue
                
            try:
                field_info = str(row.iloc[0]) if len(row) > 0 and pd.notna(row.iloc[0]) else ""
                tech_info = str(row.iloc[1]) if len(row) > 1 and pd.notna(row.iloc[1]) else ""
                
                # ì§€ì—­ë³„ ë°ì´í„° ì²˜ë¦¬
                for col_idx in range(2, len(row)):
                    if pd.notna(row.iloc[col_idx]):
                        value = str(row.iloc[col_idx]).replace(',', '')
                        if value.replace('.', '').isdigit():
                            # ì§€ì—­ëª… ì¶”ì • (ì»¬ëŸ¼ ì¸ë±ìŠ¤ ê¸°ë°˜)
                            region_names = list(region_coords.keys())
                            region = region_names[(col_idx - 2) % len(region_names)]
                            
                            coords = region_coords[region]
                            
                            processed_data.append({
                                'year': 2020,
                                'region': region,
                                'field': self.clean_field_name(field_info),
                                'tech_name': tech_info,
                                'export_count': int(float(value)),
                                'latitude': coords[0],
                                'longitude': coords[1],
                                'countries': coords[2]
                            })
            except:
                continue
        
        if processed_data:
            result_df = pd.DataFrame(processed_data)
            output_file = self.processed_dir / 'overseas_data.csv'
            result_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"   âœ… í•´ì™¸ì§„ì¶œ ë°ì´í„° ì €ì¥: {output_file} ({len(result_df)}í–‰)")
        else:
            print("   âŒ í•´ì™¸ì§„ì¶œ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
    
    def verify_processed_data(self):
        """ì²˜ë¦¬ëœ ë°ì´í„° ê²€ì¦"""
        print("\nğŸ“Š ì²˜ë¦¬ëœ ë°ì´í„° ê²€ì¦")
        print("-" * 30)
        
        processed_files = list(self.processed_dir.glob('*.csv'))
        
        for file_path in processed_files:
            try:
                df = pd.read_csv(file_path)
                print(f"âœ… {file_path.name}: {len(df)}í–‰ x {len(df.columns)}ì—´")
                
                # ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ
                if len(df) > 0:
                    print(f"   ğŸ“‹ ì»¬ëŸ¼: {list(df.columns)}")
                    print(f"   ğŸ“Š ìƒ˜í”Œ: {df.iloc[0].to_dict()}")
                print()
                
            except Exception as e:
                print(f"âŒ {file_path.name}: ì½ê¸° ì‹¤íŒ¨ - {str(e)}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    processor = RealDataProcessor()
    processor.process_all_data()
    
    print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
    print("streamlit run main.py --server.port=8502")

if __name__ == "__main__":
    main()